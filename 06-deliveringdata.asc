== 6. Delivering data ==

image::figs/incoming/06-00-cover.png[width=600]

=== Presenting Data to the Public (Various Contributors) ===

There are lots of different ways to present your data to the public - from publishing raw datasets with stories, to creating beautiful visualisations and interactive web applications. To open this section, we asked leading data journalists for tips on how to present data to the public.

*To Visualise or Not to Visalise?*

[quote, Aaron Pilhofer (New York Times)]
____
There are times when data can tell a story better than words or photos, and this is why terms like ``news application'' and ``data visualisation'' have attained buzzword status in so many newsrooms of late. Also fuelling interest is the bumper crop of (often free) new tools and technologies designed to help even the most technically challenged journalist turn data into a piece of visual storytelling.

Tools like Google Fusion Tables, Many Eyes, Tableau, Dipity and others make it easier than ever to create maps, charts, graphs or even full-blown data applications that heretofore were the domain of specialists. But with the barrier to entry now barely a speed bump, the question facing journalists now less about whether you can turn your dataset into a visualisation, but whether you should. http://www.niemanlab.org/2011/10/word-clouds-considered-harmful/[Bad data visualization] is worse in many respects than none at all.
____

*Which is the Right Visualisation for Your Story?*

[quote, Lulu Pinney (BBC)]
____
Not all types of visualisations are appropriate for all data sets. When you are deciding on a visualisation, keep in mind that you are trying to tell a story and that some types of visualisations will tell that story better than others.

A map, for example, will highlight geographical distribution of a variable, but it will suppress quantitative comparisons or changes over time. The bottom chart isn't eye candy, but it is very functional; not a single pixel is wasted. Every dot conveys information relevant to the data set, and important relationships are immediately visually evident. How much of your chart is wasted on decoration, and how much communicates information?
____

*Putting Data on Maps*

[quote, (David Erwin, New York Times)]
____
Maps can be a powerful tool to visualise data when geographical information plays a fundamental role in the telling of the story. They can be used to overlay multiple datasets to show concepts such as areas of overlap or divergence, concentrations, etc. Further, they put data in the context of the viewer's understanding of the area and, for local maps, tap into their daily experience.

Your audience must immediately (or at least clearly) intuit the information you're presenting from the visual markers. Choosing the appropriate overlays is essential. Objects can be plotted and made clickable for more information, the size of markers can be used to indicate quantity or severity (with or without a legend), overlays or polygons can represent zones.

It's important to note that the fact that data can be mapped http://www.ericson.net/content/2011/10/when-maps-shouldnt-be-maps/[does not mean that it should be mapped]. If location isn't central to the narrative, the presence of a map will probably be distracting.
____

*Using Motion Graphics*

[quote, Lulu Pinney (BBC)]
____
With a tight script, well timed animations and clear explanations motion graphics can serve to bring complex numbers or ideas to life, guiding your audience through the story. Hans Rosling's video lectures are a good example of how data can come to life to tell a story on the screen. Whether or not you agree with their methodology I also think the Economist's http://www.economist.com/blogs/multimedia/2011/02/unrest_arab_world[Shoe-throwers' index] is a good example of using video to tell a numbers-based story. You wouldn't, or shouldn't, present this graphic as a static image. There's far too much going on. But having built up to it step by step you're left with an understanding of how and why they got to this index. With motion graphics and animated shorts, you can reinforce what your audience is hearing from a voice-over with explanatory visuals provides a very powerful and memorable way of telling a story.
____

*Telling the World*

[quote, Simon Rogers (Guardian Datablog)]
____
Our workflow usually starts in Excel. It is such an easy way to quickly work out if there's something interesting in the data. If we have a sense that there is something in it then we go to the news desk.  We're really lucky as we sit right next to main news desk at the Guardian. Then we look at how we should visualise it or show it on the page. Then we write the post that goes with it. When I'm writing I usually have a cut down version of the spreadsheet next to the text editor. Often I'll do bits of analysis while I'm writing to pick out interesting things. Then I'll publish the post and spend a bit of time Tweeting about it, writing to different people and making sure that it is linked to from all the right places.

Half of the traffic from some of our posts will come from Twitter and Facebook. We're pretty proud that the average amount of time spent on a Datablog article is 6 minutes, compared to an average of 1 minute for the rest of the Guardian website. 6 minutes is a pretty good number and time spent on the page is one of the key metrics when analysing our traffic.

This also helps to convince our colleagues about the value of what we're doing. That and the big data-driven stories that we've worked on that everyone else in the newsroom knows: COINS, Wikileaks and the UK riots. For the COINS spending data, we had 5-6 specialist reporters at the Guardian working to give their views about the data when it was released by the UK Government. We also had another team of 5-6 when the UK government spending over £25k data was released - including well known reporters like Polly Curtis. Wikileaks was also obviously very big, with lots of stories about Iraq and Afghanistan. The riots was also pretty big, with over 550k hits in two days.

But it is not just about the short term hits: it is also about being a reliable source of useful information. We try to be the place where you can get good, meaningful information on topics that we cover.
____

*Publishing the Data*

[quote, Cheryl Phillips (Seattle Times)]
____
We often will embed our data onto our site in a visualisation and in a form that allows for easy download of the dataset. Our readers can explore the data behind the stories through interacting in the visualisation or using the data themselves in other ways. Why is this important? It increases the transparency of The Seattle Times. We are showing the readers the same data that we used to draw powerful conclusions. And who uses it? Our critics for sure, as well as those just interested in the story and all of its ramifications. By making the data available we also can enlist tips from these same critics and general readers on what we may have missed and what more we could explore - all valuable in the pursuit of journalism that matters.
____

*Opening up your Data*

[quote, Steve Doig (Walter Cronkite School of Journalism and Mass Communication)]
____
Giving news consumers easy access to the data we use for our work is the right thing to do for several reasons. Readers can assure themselves that we aren't torturing the data to reach unfair conclusions. Opening up our data is in the social science tradition of allowing researchers to replicate our work. Encouraging readers to study the data can generate tips that may lead to follow-up stories. Finally, engaged readers interested in your data are likely to return again and again.
____

*Starting an Open Data Platform*

[quote, Peralta Ramos Momi (La Nacion)]
____
At La Nacion publishing open data is an integral part of our data journalistic activities. In Argentina there is no Freedom of Information Act and no national data portal, so we feel strongly about providing our readers with access to the data that we use in our stories.

Hence we publish raw structured data through our integrated http://data.lanacion.com.ar[Junar] platform as well as in Google Spreadsheets. We explicitly enable and encourage others to reuse our data, and we explain a bit about how to do this with http://blogs.lanacion.com.ar/data/argentina/la-nacion-abre-sus-bases-de-datos-de-interes-publico/[documentation and video tutorials].

Furthermore we're presenting some of these datasets and visualisations in our http://blogs.lanacion.com.ar/data/[NACION Data blog]. We're doing this in order to evangelise about data and data publishing tools in Argentina, and show others how we gathered our data, how we use it and how they can reuse it.

Since we opened the platform in February 2012 , we've received suggestions and ideas for datasets, mostly from academic and research people, as well as students from universities that are very thankful every time we reply with a solution or specific dataset. People are also engaging with and commenting on our data on Tableau and several times we have been the most commented and top viewed item on the service. In 2011 we had http://www.tableausoftware.com/public/blog/2012/02/top-vizzes-q4-2011-1442[7 out of the top 100] most viewed visualisations.
____

*Making Data Human*

[quote, Jer Thorp (Data Artist in Residence, The New York Times R&D Group)]
____
As the discussion around big data bounds into the broader conscious, one important part has been conspicuously missing - the human element. While many of us think about data as disassociated, free-floating numbers, they are in fact measurements of tangible (and very often human) things. Data are tethered to real lives of real people, and when we engage with the numbers, we must consider the real-world systems from which they came.

Take, for example, location data - which is being collected right now on hundreds of millions of phones and mobile devices. It's easy to think of these data (numbers that represent latitude, longitude, and time) as `digital exhaust', but they are in fact distilled moments from our personal narratives. While they may seem dry and clinical when read in a spreadsheet, when we allow people to put their own on a map and replay them, they experience a kind of memory replay that is powerful and human.

At the moment, location data is used by a lot of `third parties' - application developers, big brands, and advertisers. While the `second parties' (telecoms & device managers) own and hold the data, the `first party' in this equation - you - has neither access or control over this information. At the NYTimes R&D group, we have launched a prototype project called OpenPaths (openpaths.cc) to both allow the public to explore their own location data, and to experience the concept of data ownership. After all, people should have control of these numbers that are so closely connected to their own lives and experiences.

Journalists have a very important role in bringing this inherent humanity of data to light. By doing so, they have the power to change public understanding - both of data and of the systems from which the numbers emerged.
____

=== How to Build a News App (Chase Davis, Center for Investigative Reporting) ===

image::figs/incoming/06-AA.png[width=600]

News applications are windows into the data behind a story. They might be searchable databases, sleek visualisations or something else altogether. But no matter what form they take, news apps encourage readers to interact with data in a context that is meaningful to them: looking up crime trends in their area, checking the safety records of their local doctor, or searching political contributions to their candidate of choice. 

More than just high-tech infographics, the best news apps are durable products. They live outside the news cycle, often by helping readers solve real-world problems, or answering questions in such a useful or novel way that they become enduring resources. When journalists at ProPublica wanted to explore the safety of American kidney dialysis clinics, they built http://projects.propublica.org/dialysis/[an application] that helped users check whether their hometown facility was safe. Providing such an important and relevant service creates a relationship with users that reaches far beyond what a narrative story can do alone.

Therein lies both the challenge and the promise of building cutting-edge news apps: creating something of lasting value.  Whether you are a developer or a manager, any discussion about how to build a great news app should start with a product development mentality: Keep a laser focus on the user, and work to get the most bang for your buck. So before you start building, it helps to ask yourself three questions:

**1. Who is my audience and what are their needs?**

News apps don't serve the story for its own sake – they serve the user. Depending on the project, that user might be a dialysis patient who wants to know about the safety record of her clinic, or even a homeowner unaware of earthquake hazards near his home. No matter who it is, any discussion about building a news app, like any good product, should start with the people who are going to use it.

A single app might serve many users. For instance, a project called http://curbwise.com/[Curbwise], built by the Omaha (Nebraska) World-Herald serves homeowners who believe they are being overtaxed; curious residents who are interested in nearby property values; and real estate workers trying to keep track of recent sales. In each of those cases, the app meets a specific need that keeps users coming back.

Homeowners, for instance, might need help gathering information on nearby properties so they can argue that their taxes are unfairly high. Pulling together that information is time-consuming and complicated – a problem Curbwise solves for its users by compiling a http://curbwise.com/how-to-protest[user-friendly report] of all the information they need to challenge their property taxes to local authorities. Curbwise sells that report for $20, and people pay for it because it solves a real problem in their lives.

Whether your app solves a real-world problem like Curbwise or supplements the narrative of a story with an interesting visualisation, always be aware of the people who will be using it. And then concentrate on designing and building features based on their needs.

**2. How much time should I spend on this?**

Developers in the newsroom are like water in the desert: highly sought after and in short supply. Building news apps means balancing the daily needs of a newsroom against the long-term commitments it takes to build truly great products.

Say your editor comes to you with an idea: The City Council is set to have a vote next week about whether to demolish several historic properties in your town. He suggests building a simple application that allows users to see the buildings on a map.

As a developer, you have a few options. You can flex your engineering muscle by building a gorgeous map using custom software. Or you can use existing tools like Google Fusion Tables or open source mapping libraries and finish the job in a couple hours. The first option will give you a better app; but the second might give you more time to build something else with a better chance of having a lasting impact.

Just because a story lends itself to a complex, beautiful news app doesn't mean you need to build one. Balancing priorities is critical. The trick is to remember that every app you build comes at a cost: namely, another potentially more impactful app you could have been working on instead. 

**3. How can I take things to the next level?**

Building high-end news apps can be time-consuming and expensive. That's why it always pays to ask about the payoff. How do you elevate a one-hit wonder into something special?

Creating an enduring project that transcends the news cycle is one way. But so is building a tool that saves you time down the road (and open sourcing it!), or applying advanced analytics to your app to learn more about your audience.

Lots of organizations build Census maps to show demographic shifts in their cities. But when the Chicago Tribune news apps team http://media.apps.chicagotribune.com/chicago-census/less-than-five.html[built theirs], they took things to the next level by developing tools and techniques to build those maps quickly, which they then http://blog.apps.chicagotribune.com/2011/03/08/making-maps-1/[made available] for other organizations to use.

At my employer, the Center for Investigative Reporting, we coupled a simple searchable database with a fine-grained event tracking framework that allowed us to learn, among other things, how much users value serendipity and exploration in our news apps.

At the risk of sounding like a bean-counter, always think about http://cironline.org/blog/post/beyond-three-ps-few-more-thoughts-business-news-apps[return on investment]. Solve a generic problem; create a new way to engage users; open source parts of your work; use analytics to learn more about your users; or even find cases like Curbwise where part of your app might generate revenue.

**Wrapping up**

News application development has come a long way in a very short time. News Apps 1.0 were a lot like Infographics 2.0 – interactive data visualizations, mixed with searchable databases, designed primarily to advance the narrative of the story. Now, many of those apps can be designed by reporters on deadline using open source tools, freeing up developers to think bigger thoughts.

News Apps 2.0, where the industry is headed, is about combining the storytelling and public service strengths of journalism with the product development discipline and expertise of the technology world. The result, no doubt, will be an explosion of innovation around ways to make data relevant, interesting and especially useful to our audience – and at the same time hopefully helping journalism do the same.

=== News Apps at ProPublica (Scott Klein, ProPublica) ===

A news application is a big interactive database that tells a news story. Think of it like you would any other piece of journalism. It just uses software instead of words and pictures.

By showing each reader data that is specific to them, a news app can help each reader understand a story in a way that's personally meaningful to them. It can help a reader understand their personal connection to a broad national phenomenon, and help them attach what they know to what they don't know, and thereby encourage a deep understanding of abstract concepts.

We tend to build news apps when we have a dataset (or think we can acquire a dataset) that is national in scope yet granular enough to expose meaningful details.

A news app should tell a story, and just like any good news story, it needs a headline, a byline, a lead, and a nut graph. Some of these concepts can be hard to distinguish in a piece of interactive software, but they're there if you look closely.

Also, a news app should be generative - meaning it should generate more stories and more reporting. ProPublica's best apps have been used as the basis for local stories.

For instance, take our http://projects.propublica.org/docdollars[Dollars for Docs] news app. It tracked, for the first time, millions of dollars of payments by drug companies to doctors - for consulting, speaking, and so on. The news app we built lets readers look up their own doctor and see the payments they've received. Reporters at other news organisations also used the data. More than 125 local news organisations, including the Boston Globe, Chicago Tribune and the St. Louis Post-Dispatch did investigative stories on local doctors based on Dollars for Docs data.

A few of these local stories were the result of formal partnerships, but the majority were done quite independently – in some cases, we didn't have much if any knowledge that the story was being worked on until it came out. As a small but national news organisation, this kind of thing is crucial for us. We can't have local knowledge in 125 cities, but if our data can help reporters who have local knowledge tell stories with impact, we're fulfilling our mission.

image::figs/incoming/06-FF.png[width=600]

One of my favourite news apps is the Los Angeles Times's http://projects.latimes.com/mapping-la/neighborhoods/[Mapping L.A.], which started out as a crowdsourced map of Los Angeles's many neighbourhoods, which up until Mapping L.A. launched had no independent, widely-accepted set of boundaries. After the initial crowdsourcing project, the Times has been able to use neighbourhoods as a framing device for great data reporting - things like crime rate by neighbourhood, school quality by neighbourhood, etc., which they wouldn't have been able to do before. So not only is Mapping L.A. both broad and specific, it's generative, and it tells people's own stories.

The resources necessary to build a news app range pretty widely. The New York Times has dozens of people working on news apps and on interactive graphics. But http://polltracker.talkingpointsmemo.com/[Talking Points Memo] made a cutting edge political poll tracker app with two staffers, neither of whom had computer science degrees.

Like most newsroom-based coders, we follow a modified Agile methodology to build our apps. We iterate quickly and show drafts to the other folks in the newsroom we're working with. Most importantly we work really closely with reporters and read their drafts - even early ones. We work much more like reporters than like traditional programmers. In addition to writing code, we call sources, gather information and build expertise. It would be pretty difficult to make a good news app using material we don't understand.

Why should newsrooms be interested in producing data-driven news apps? Three reasons: It's great journalism, it's hugely popular - ProPublica's most popular features are news apps - and if we don't do it somebody else will. Think of all the scoops we'd miss! Most importantly, newsrooms should know that they can all do this too. It's easier than it looks.

=== Visualisation as the Workhorse of Data Journalism (Sarah Cohen, Washington Post) ===

Before you launch into trying to chart or map your data, take a minute to think about the many roles that static and interactive graphic elements play in your journalism.

In the reporting phase, visualisations can:

  * Help you identify themes and questions for the rest of your reporting
  * Identify outliers - good stories, or perhaps errors, in your data
  * Help you find typical examples
  * Show you holes in your reporting

Visualisations also play multiple roles in publishing:

  * Illustrate a point made in a story in a more compelling way
  * Remove unnecessarily technical information from prose
  * Particularly when they are interactive and allow exploration, provide transparency about your reporting process to your readers

These roles suggest you should start early and often with visualisations in your reporting, whether or not you start electronic data or records. Don't consider it a separate step – something to be considered after the story is largely written. Let this work help guide your reporting.

Getting started sometimes means just putting in a visual form the notes you've already taken. Consider this graphic, which ran in the Washington Post in 2006:

////
image::figs/incoming/06-MM.png[width=600]
////

It shows the portion of farm income associated with subsidies and key events over the past 45 years, and was built over a series of months. Finding data that could be used over time with similar definitions and similar meanings was a challenge. Investigating all of the peaks and troughs helped us keep context in mind as we did the rest of our reporting. It also meant that one chore was pretty much finished before the stories were written.

*TIPS FOR EXPLORATION*

Here are some tips for using visualisation to start exploring your datasets.

*1. Use Small Multiples to Quickly Orient Yourself in a Large Dataset*

I used this technique at the Washington Post when we were looking into a tip that the George W. Bush administration was awarding grants on political, not substantive, grounds. Most of these aid programs are done by formula, and others have been funded for years, so we were curious whether we might see the pattern by looking at nearly 1,500 different discretionary streams.

////
image::figs/incoming/06-NN.png[width=600] 
////

I created a graph for each program, with the red dots indicating a presidential election year and the green dots indicating a congressional year. The problem: Yes, there was a spike in the six months before the presidential election in several of these programs - the red dots with the peak numbers next to them – but it's the wrong election year. Instead of George W. Bush's re-election bid, the peak as consistently for the 2000 presidential election, when Bill Clinton was in the White House and his vice president, Al Gore, was running for the office.

This was really easy to see in a series of graphs rather than a table of numbers, and an interactive form let us check various types of grants, regions and agencies. Maps in small multiples can be a way to show time and place on a static image that's easy to compare - sometimes even easier than an interactive.

This example was created with a short program written in PHP, but it's now much easier to do with Excel 2007 and 2010's sparklines. Edward Tufte, the visualisation expert, invented these ``intense, simple, word-like graphics'' to convey information in a glance across a large dataset. You now see them everywhere, from the little graphs under stock market quotations to win-loss records in sports.

*2. Look at Your Data Upside Down and Sideways*

When you're trying to understand a story or a dataset, there's no wrong way to look at it - try it every way you can think of, and you'll get a different perspective. If you're reporting on crime, you might look at one set of charts with change in violent crimes in a year; another might be the percent change; the other might be a comparison to other cities; and another might be a change over time. Use raw numbers, percentages and indexes.

Look at them on different scales. Try following the rule that the x-axis must be zero. Then break that rule and see if you learn more. Try out logarithms and square roots for data with odd distributions.

Keep in mind the research done on visual perception. William Cleveland's experiments showed that the eye sees change in an image when the average slope is about 45 degrees. This suggests you ignore the admonitions to always start at zero and instead work toward the most insightful graphic.  Other research in epidemiology has suggested you find a target level as a boundary for your chart.  Each of these ways helps you see the data in different ways. When they've stopped telling you anything new, you know you're done.

*3. Don't Assume*

Now that you've looked at your data a variety of ways, you've probably found records that don't seem right - you may not understand what they meant in the first place, or there are some outliers that seem like they are typos, or there are trends that seem backwards.

If you want to publish anything based on your early exploration or in a published visualisation, you have to resolve these questions and you can't make assumptions. They're either interesting stories or mistakes; interesting challenges to common wisdom or misunderstanding.

It's not unusual for local governments to provide spreadsheets filled with errors, and it's also easy to misunderstand government jargon in a dataset.

First, walk back your own work. Have you read the documentation, its caveats and does the problem exist in the original version of the data? If everything on your end seems right, then it's time to pick up the phone. You're going to have to get it resolved if you plan to use it, so you might as well get started now.

That said, not every mistake is important. In campaign finance records, it's common to have several hundred postal codes that don't exist in a database of 100,000 records. As long as they're not all in the same city or within a candidate, the occasional bad data record just doesn't matter.

The question to ask yourself is: if I were to use this, would readers have a fundamentally accurate view of what the data says?

*4. Avoid Obsessing Over Precision*

The flip side of not asking enough questions is obsessing over precision before it matters.  Your exploratory graphics should be generally correct, but don't worry if you have various levels of rounding, if they don't add up to exactly 100 percent or if you are missing one or two years' data out of 20. This is part of the exploration process. You'll still see the big trends and know what you have to collect before it's time for publication.

In fact, you might consider taking away labelling and scale markers, much like the charts above, to even better get an overall sense of the data.

*5. Create chronologies of cases and events*

At the start of any complex story, begin building chronologies of key events and cases. You can use Excel, a Word document or a special tool like TimeFlow for the task, but at some point you will find a dataset you can layer behind it. Reading through it periodically will show you what holes are in your reporting that have to be filled out.

*6. Meet with your graphics department early and often*

Brainstorm about possible graphics with the artists and designers in your newsroom. They will have good ways to look at your data, suggestions of how it might work interactively, and know how to connect data and stories. It will make your reporting much easier if you know what you have to collect early on, or if you can alert your team that a graphic isn't possible when you can't collect it.

*TIPS FOR PUBLICATION*

You might have spent only a few days or few hours on your exploration, or your story might have taken months to report. But as it becomes time to move to publication, two aspects become more important.

Remember that missing year you had in your early exploration? All of a sudden, you can't go any further without it.  All of that bad data you ignored in your reporting? It's going to come back to haunt you.
 
The reason is that you can't write around bad data. For a graphic, you either have everything you need or you don't, and there's no middle ground. 

*1. Match the Effort of the Data Collection with the Interactive Graphic*

There's no hiding in an interactive graphic. If you are really going to have your readers explore the data any way they want, then every data element has to be what it claims to be. Users can find any error at any time, and it could haunt you for months or years.

If you're building your own database, it means you should expect to proof read, fact check and copy edit the entire database. If you're using government records, you should decide how much spot-checking you'll do, and what you plan to do when you find the inevitable error.

*2. Design for Two Types of Readers*

The graphic - whether it's a standalone interactive feature or a static visualisation that goes with your story - should satisfy two different kinds of readers. It should be easy to understand at a glance, but complex enough to offer something interesting to people who want to go further. If you make it interactive, make sure your readers get something more than a single number or name.

*3. Convey One Idea – Then Simplify*

Make sure there is one single thing you want people to see? Decide on the overwhelming impression you want a reader to get, and make everything else disappear. In many cases, this means removing information even when the Internet allows you to provide everything. Unless your main purpose is in transparency of reporting, most of the details you collected in your timeline and chronology just aren't very important. In a static graphic, it will be intimidating. In an interactive graphic, it will be boring.

=== Using Visualisations to Tell Stories (Geoff McGhee, Stanford University) ===

Waiting for text.

=== How Data Visualisation is Used at the Most Read Daily Newspaper in Norway (John Bones, Verdens Gang) ===

News journalism is about bringing new information to the reader as quickly as possible. The fastest way may be a video, a photo, a text, a graph, a table or a combination of these. Concerning visualisations, the purpose should be the same: quick information. New data tools enable journalists to find stories they couldn't otherwise find, and present stories in new ways. Here are a few examples showing how data visualisation is used in the most read newspaper in Norway, Verdens Gang (VG).

*1. When the Visualisation is the Story*

_Here is Crime Happening - Hour by Hour_

image::figs/incoming/06-BB.png[width=600]

In [this animated heatmap combined with a simple bar chart](http://www.vgtv.no/#!id=46131) you can watch see crime incidents occur on a map of downtown Oslo, hour by hour, over the weekend for several months. In the same animated heatmap, you can see the number of police officers working at the same time. When crime really is happening, the number of police officers is at the bottom.

Tools used: ArcView with Spatial Analyst.

*2. When the Visualisation Helps us Find the story*
 
_The Network of Movie Stars_

In this Social Network Analysis, VG downloaded all relations in all Norwegian movies during more than ten years. Who acts with whom, and which actors work with different directors? A database with all relevant content was exported to UCINET, a program for social network analysis. It was then quite easy to see who was connected with whom, with different strength of ties.

_Rich children are playing together_

The same methods were used when downloading 157 lists of friends from Facebook. These 157 people were sons and daughters of the richest people in Norway, and the social network analysis showed that heirs of the richest persons in Norway also inherited their parents' network. The graphics were all finished manually using Photoshop.

Tools used: Access, Excel Notepad, Ucinet.

Lessons: When making social network analysis, we get an enormous amount of data. When making the presentation, we had to do a lot of manual work at the end.

Anecdotes: The most central person in the movie network denied there was a network!

**3. When the Visualisation is Telling the Story**
 
_Out of the Ghetto_

One story looked at internal migration in Oslo, based on data from The Norwegian Bureau of Statistics. The angle for the story is the development among the biggest immigration groups in Oslo, and the reader does not have to read the text to understand the news.

Tools used: Excel, Access, ArcView.

Lessons learned: Too much text on the pages. It would have been better to concentrate 100 percent on the graphs.

**4. When the Visualisation is Supplying the Text**
 
_Erna is the Queen of Applause_

For http://www.vg.no/nyheter/innenriks/valg-2009/artikkel.php?artid=570321[this visualization] we text mined speeches held by the seven Norwegian party leaders during their conventions. All speeches were analysed, and the analyses supplied angles for some stories. Every story was linked to the graph, and the readers could explore and study the language of politicians.

Tools used: Excel, Access, Flash and Illustrator.

Lessons: In 2012 we would have made the interactive graph in Javascript.

We do not yet have good tools for text mining.

**5. When the Visualisation is an Integrated Part**
 
Mekka of the slots in the north (of Norway)

This story is about the use of slots in the different parts of Norway. The text, the tables, the graph and the photo are all parts of an integrated solution.

Tools used: Most important was Access database. The mapping solution is made in ArcView.

**6. When the Graphs are Interactive:**
 
_Here People are Using Most of their Income on Lotto_

http://www.vg.no/nyheter/innenriks/artikkel.php?artid=569832[This story] is based on data from the Norwegian Bureau of Statistics, taxpayers data and data from the national Lotto monopolist. In this interactive graph, the reader could find different kinds of information from each Norwegian county and municipality. The actual table is showing the percent of the income used on games.

Tools used: Access, Excel, MySql, Flash
 
Translation of the column titles: Pristilskudd = price given by the dairy.
Produksjonstilskudd = national subsidies
Link: http://www.vg.no/spesial/jordbrukstilskudd/

The data in this table is containing farm subsidies to all Norwegian farmers, some 46 000. By clicking at the drop down menu at the top of the graph, the readers could choose county and municipality.
Tools used: Access, Excel, MySql.
Lessons learned: This table and the stories connected to it was the most read that day. The graphs do not necessarily need to be fancy to capture readers.

**7. When the Visualisation is User-generated:**
 
_Here People Are Most Afraid in Oslo_

http://www.vg.no/nyheter/innenriks/artikkel.php?artid=10091789[This Google heat map] is based upon information given by 16 000 readers. There had been several rapes downtown Oslo, and the readers could click at a Google map to show were in Oslo they did not feel safe.

Tools used: Google Fusion Tables with heatmap, Google maps, MySql. 

*Concluding Notes*

When do we need to visualise a story? Most of the times we do not need to do it, but sometimes we want to do so to help our readers. Stories containing a huge amount of data quite often need visualisation. However, we have to be quite critical when choosing what kind of data we are going to present. We know all kinds of stuff when we report about something, but does the reader really need to know for the story? Perhaps a table is enough, or a simple graph showing a development from year A to year C. When working with data journalism, the point is not necessarily to present huge amounts of data. It's about journalism!

There has been a clear trend in last 2-3 years to create interactive graphs and tables which enable the reader to drill down into different themes. A good visualisation is like a good picture. You understand what it is about just by looking at it for a moment or two. The more you look at the visual the more you see. The visualisation is bad when the reader does not know where to start or where to stop, and when the visualisation is overloaded by details. In this scenario, perhaps a piece of text would be better?

=== Public Data Goes Social (Oluseun Onigbinde, BudgIT Nigeria) ===

Data is invaluable. Access to data has the potential to illuminate issues in a way which triggers results. Nevertheless, poor handling of data can put facts in an opaque structure which communicates nothing. If it doesn't promote discussion or provide contextual understanding, data may be of limited value to the public.

Nigeria returned to democracy in 1999 after lengthy years of military rule. Probing the facts behind data was taken as an affront to authority and was seen to be trying question the stained reputation of the junta. The Official Secrets Act compelled civil servants not to share government information. Even after thirteen years of return to democracy, accessing public data can be a difficult task. Data about public expenditure communicates little to the majority of the public who are not well versed in financial accounting and complex arithmetic. 

With the rise of mobile devices and an increasing number of Nigerians online, with BudgIT we saw a huge opportunity to use use data visualisation technologies to explain and engage people around public expenditure. To do this we have had to engage users across all platforms and to reach out to citizens via NGOs. This project is about making public data a social object and building an extensive network that demands change.

image::figs/incoming/06-YY.png[width=600]

To successfully engage with users, we have to understand what they want. What does the Nigerian citizen care about? Where do they feel an information gap? How can we make the data relevant to their lives? BudgIT's immediate target is the average literate Nigerian connected to online forums and social media. In order to compete for the limited attention of users immersed in a wide variety of interests (gaming, reading, socialising) we need to present the data in a brief and concise manner. After broadcasting a snapshot of the data as a Tweet or an infographic, there's an opportunity for a more sustained engagement with a more interactive experience to give users a bigger picture.

When visualising data it is important to understand the level of data literacy of our users. As beautiful and sophisticated as they may be, complex diagrams and interactive applications might not meaningfully communicate to our users based on their previous experiences with interpreting data. A good visualisation will speak to the user in a language they can understand, and bring forth a story that they can easily connect with.

We have engaged over 10,000 Nigerians over the budget and we profile them into three categories to ensure that optimum value is delivered. The categories are briefly explained below:

  * _Occasional Users_. These are users who want information simply and quickly. They are interested in getting a picture of the data, not detailed analytics. We can engage them via Tweets or interactive graphics.
  * _Active Users_. Users who stimulate discussion, and use the data to increase their knowledge of a given area or challenge the assumptions of the data. For these users we want to provide feedback mechanisms and the possibility to share insights with their peers via social networks.
  * _Data Hogs_: These users want raw data for visualisation or analysis. We simply give them the data for their purposes.

image::figs/incoming/06-ZZ.png[width=600]

With BudgIT, our user engagement is based on the following: 

  * _Stimulating Discussion Around Current Trends_. BudgIT keeps track of online and offline discussions and seeks to provide data around these topics. For example, with the fuel strikes in January 2012 there was constant agitation among the protesters on the need to reinstate fuel subsidies and reduce extravagant and unnecessary public expenditure. BudgIT tracked the discussion via social media and in 36 busy hours built an app that allows citizens to reorganise the Nigerian budget.
  * _Good Feedback Mechanisms_. We engage with users through discussion channels and social media. Many users want to know about stories behind the data and many ask for our opinion. We make sure that our responses only explain the facts behind the data and our not biased by our personal or political views. We need to keep feedback channels open, to actively respond to comments and to engage the users creatively to ensure the community built around the data is sustained.
  * _Make it Local_. For a dataset targeted at a particular group, BudgIT aims to localise its content and to promote a channel of discussion that connects to the needs and interests of particular groups of users. In particular we're interested in engaging users around issues they care about via SMS.

After making expenditure data available on yourbudgit.com, we reach out to citizens through various NGOs. We also plan to develop a participatory framework where citizens and government institutions can meet in town halls to define key items in the budget that needs to be prioritised. 

The project has received coverage in local and foreign media, from http://www.cp-africa.com/2012/01/13/budgit-launches-cut-government-waste-application-for-the-2012-nigerian-budget/[CP-Africa] to the http://www.bbc.co.uk/news/world-africa-16591389[BBC]. We have undertaken a review of 2002-2011 budget for the security sector for an AP journalist, Yinka Ibukun. Most media organisations are `data hogs' and have requested data from us to use for their reportage. We are planning further collaborations with journalists and news organisations in the coming months.

=== Engaging Your Audience (Duncan Geere, Wired.co.uk) ===

Almost as important as publishing the data in the first place is getting a reaction from your audience. You're human - you're going to make mistakes, miss things and get the wrong idea from time to time. Your audience is one of the most useful assets that you've got - they can fact-check and point out things that you may not have considered.

Engaging that audience is tricky, though. You're dealing with a group of people who've been conditioned over years of internet use to hop from site to site, leaving nothing but a sarcastic comment in their wake. Building a level of trust between you and your users is crucial - they need to know what they're going to get, know how they can react to it and offer feedback, and know that that feedback is going to be listened to.

But first you need to think about what audience you've got, or want to get. That will both inform and be informed by the kind of data that you're working with. If it's specific to a particular sector, then you're going to want to explore particular communications with that sector. Are there trade bodies that you can get in touch with that might be willing to publicise the resources that you've got and the work that you've done to a wider audience? Is there a community website or a forum that you can get in touch with?

Social media is an important tool, too, though it again depends on the type of data that you're working with. If you're looking at global shipping statistics, for example, you're unlikely to find a group on Facebook or Twitter that'll be especially interested in your work. On the other hand if you're sifting through corruption indices across the world, or local crime statistics, that's likely to be something that's going to be of interest to a rather wider audience.

Then you need to think about how those people are going to interact with your work. Sure, they might read the story that you've written and look at the infographics or maps, but giving your users an outlet to respond is immensely valuable. More than anything it's likely to give you greater insight into the subject you're writing about, informing future work on the topic.

It goes without saying that you need to publish the raw data alongside your articles, but think about if there's other ways that you can get the audience to interact. Keep an eye on metrics on which parts of your datasets are getting attention - it's likely that the most trafficked areas could have something to say that you might have missed.

Think beyond the comment box, too. Can you attach comments to particular cells in a spreadsheet? Or a particular region of an infographic? Make sure that other users can see those comments too - they have almost as much value as the original data, in a lot of cases.

Finally, other people might want to publish their own infographics and stories on the same sources of data - think about how best to tie that information together. You could use a hashtag specific to the dataset, for example, or if it's highly pictorial then you could share it in a Flickr group. Having a route to share information more confidentially could be useful too -- in some cases it might not be safe for people to publicly share their contributions to a dataset, or they might simply not be comfortable doing so.